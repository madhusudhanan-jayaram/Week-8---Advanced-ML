{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3696b9c-589b-41b2-9dac-673be2f60049",
   "metadata": {},
   "source": [
    "# üìò RFE Regression Notebook\n",
    "\n",
    "This notebook demonstrates **Recursive Feature Elimination (RFE)** for feature selection  \n",
    "and compares the performance of different regression models:\n",
    "\n",
    "- **Linear Regression**\n",
    "- **Support Vector Regression (SVR ‚Äì Linear & Non-Linear kernels)**\n",
    "- **Decision Tree Regressor**\n",
    "- **Random Forest Regressor**\n",
    "\n",
    "### Workflow:\n",
    "1. Load and preprocess the dataset (scaling, splitting).\n",
    "2. Apply **RFE** to select the top `n` most important features.\n",
    "3. Train multiple regression models on the reduced feature sets.\n",
    "4. Evaluate model performance using **R¬≤ scores**.\n",
    "5. Summarize results in a comparison table.\n",
    "\n",
    "### Key Insight:\n",
    "- **RFE** helps reduce noise and improve model focus.  \n",
    "- In most cases, **Random Forest** and **Decision Tree** perform better than linear models.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "258089c0-cd08-4678-b1cf-3230dc452945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961b37af-59a9-415a-aefd-9794128214cb",
   "metadata": {},
   "source": [
    "### Data Split & Scaling  \n",
    "Splits the dataset into training (75%) and testing (25%), then applies StandardScaler to normalize features.  \n",
    "Returns scaled X_train, X_test along with y_train and y_test.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f67e442-9b4a-4b49-a178-fe13df13c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_scalar(indep_X,dep_Y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size = 0.25, random_state = 0)\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(indep_X,dep_Y, test_size = 0.25, random_state = 0)\n",
    "        \n",
    "        #Feature Scaling\n",
    "        #from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)    \n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73a9bb-174e-435e-b3ec-6f4e3e7cc532",
   "metadata": {},
   "source": [
    "### R¬≤ Prediction  \n",
    "Uses the trained regressor to predict on X_test, compares with y_test,  \n",
    "and returns the R¬≤ score as a measure of model accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30654f76-cabc-490f-b1a1-7c77e5f98d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_prediction(regressor,X_test,y_test):\n",
    "     y_pred = regressor.predict(X_test)\n",
    "     from sklearn.metrics import r2_score\n",
    "     r2=r2_score(y_test,y_pred)\n",
    "     return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b58035-a194-4e31-bedd-2d46b25dce5a",
   "metadata": {},
   "source": [
    "### Linear Regression Model  \n",
    "Fits a Linear Regression model on training data,  \n",
    "predicts on test data, and returns the R¬≤ score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3805600-6406-4111-8659-68118531b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        regressor = LinearRegression()\n",
    "        regressor.fit(X_train, y_train)\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return  r2   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66ddf1d-9801-4dff-896b-f494aacbbac3",
   "metadata": {},
   "source": [
    "### SVM (Linear Kernel)  \n",
    "Fits an SVR model with a linear kernel on training data,  \n",
    "predicts on test data, and returns the R¬≤ score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bd74844-3d28-47f1-9bab-a03c6d9e96c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_linear(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVR\n",
    "        regressor = SVR(kernel = 'linear')\n",
    "        regressor.fit(X_train, y_train)\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return  r2  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e195d-14ac-4cac-89ce-28f6c44bbf04",
   "metadata": {},
   "source": [
    "### SVM (Non-Linear Kernel)  \n",
    "Fits an SVR model with an RBF kernel on training data,  \n",
    "predicts on test data, and returns the R¬≤ score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40316176-b74f-4418-a6b8-4a6df5f8cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_NL(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVR\n",
    "        regressor = SVR(kernel = 'rbf')\n",
    "        regressor.fit(X_train, y_train)\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return  r2  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e4bd5f-d068-40e9-95a7-a7cb4ef440c3",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor  \n",
    "Fits a Decision Tree Regressor on training data,  \n",
    "predicts on test data, and returns the R¬≤ score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b6c480c-5458-458a-a91e-001268fd8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decision(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training setC\n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "        regressor = DecisionTreeRegressor(random_state = 0)\n",
    "        regressor.fit(X_train, y_train)\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return  r2  \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f79eec3-aceb-4280-974a-a274f2b7026a",
   "metadata": {},
   "source": [
    "### Random Forest Regressor  \n",
    "Fits a Random Forest Regressor with 10 trees on training data,  \n",
    "predicts on test data, and returns the R¬≤ score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e30706c-a54d-4ef3-8a66-a1d1f3f5761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "        regressor.fit(X_train, y_train)\n",
    "        r2=r2_prediction(regressor,X_test,y_test)\n",
    "        return  r2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e223378a-399f-4ba9-9190-b785809ae5d6",
   "metadata": {},
   "source": [
    "### RFE Feature Selection  \n",
    "Runs Recursive Feature Elimination (RFE) with multiple regressors  \n",
    "(Linear, SVM, Decision Tree, Random Forest) to select the top `n` features.  \n",
    "Returns a list of transformed feature sets (`rfelist`) for further model training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca417793-7996-466a-b8d1-0048fe3bd159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfeFeature(indep_X, dep_Y, n):\n",
    "    rfelist=[]\n",
    "    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lin = LinearRegression()\n",
    "    \n",
    "    from sklearn.svm import SVR\n",
    "    SVRl = SVR(kernel = 'linear')\n",
    "    \n",
    "    from sklearn.svm import SVR\n",
    "    #SVRnl = SVR(kernel = 'rbf')\n",
    "    \n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    dec = DecisionTreeRegressor(random_state = 0)\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    rf = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "    \n",
    "    rfemodellist=[lin, SVRl, dec, rf] \n",
    "    for i in rfemodellist:\n",
    "        print(i)\n",
    "        log_rfe = RFE(estimator=i, n_features_to_select=n)\n",
    "        log_fit = log_rfe.fit(indep_X, dep_Y)\n",
    "        log_rfe_feature = log_fit.transform(indep_X)\n",
    "        rfelist.append(log_rfe_feature)\n",
    "    return rfelist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929d1789-a3ac-42f4-a0a2-4fdc9de0fbd8",
   "metadata": {},
   "source": [
    "### RFE Regression Results  \n",
    "Creates a DataFrame to compare R¬≤ scores of all models  \n",
    "(Linear, SVM, Decision Tree, Random Forest) across RFE-selected features.  \n",
    "Returns the result table for analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "095c45fe-818c-4622-996f-d97dc4691ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_regression(acclog,accsvml,accdes,accrf): \n",
    "    \n",
    "    rfedataframe=pd.DataFrame(index=['Linear','SVC','Random','DecisionTree'],columns=['Linear','SVMl',\n",
    "                                                                                        'Decision','Random'])\n",
    "\n",
    "    for number,idex in enumerate(rfedataframe.index):\n",
    "        \n",
    "        rfedataframe['Linear'][idex]=acclog[number]       \n",
    "        rfedataframe['SVMl'][idex]=accsvml[number]\n",
    "        rfedataframe['Decision'][idex]=accdes[number]\n",
    "        rfedataframe['Random'][idex]=accrf[number]\n",
    "    return rfedataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c08a64-7018-4c8a-bd1e-592cd6bb8187",
   "metadata": {},
   "source": [
    "### Reading and Preprocessing the Dataset\n",
    "\n",
    "- Load data from `prep.csv`  \n",
    "- Create another variable `df2`  \n",
    "- Convert categorical columns into dummy variables (0/1) using `pd.get_dummies()`  \n",
    "- Use `drop_first=True` to avoid duplicate category columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63fc2e89-fcc5-4cc3-9520-5ede2dd30af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1=pd.read_csv(\"prep.csv\",index_col=None)\n",
    "df2=dataset1\n",
    "df2 = pd.get_dummies(df2, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac6ff48-595a-436f-a50d-e76ecc894215",
   "metadata": {},
   "source": [
    "### Splitting Features and Target\n",
    "\n",
    "- `indep_X` ‚Üí all independent features (X values)  \n",
    "- `dep_Y` ‚Üí the dependent/target variable (y value)  \n",
    "- We drop the column `classification_yes` from features,  \n",
    "  and keep it separately as the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e58706b-d820-41bf-b847-fc24de3f4f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_X = df2.drop('classification_yes', axis=1)  \n",
    "dep_Y   = df2['classification_yes']            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ad98b-8635-4cf2-a367-148a9528da32",
   "metadata": {},
   "source": [
    "### Running RFE (Recursive Feature Elimination) and storing accuracies\n",
    "\n",
    "- `rfelist = rfeFeature(indep_X, dep_Y, 3)`  \n",
    "  ‚Üí Run RFE to select the top 3 features from `indep_X` against target `dep_Y`.\n",
    "\n",
    "- Create empty lists to store model accuracies:  \n",
    "  - `acclin`   ‚Üí accuracy of Logistic Regression  \n",
    "  - `accsvml`  ‚Üí accuracy of SVM (linear kernel)  \n",
    "  - `accsvmnl` ‚Üí accuracy of SVM (non-linear kernel)  \n",
    "  - `accdes`   ‚Üí accuracy of Decision Tree  \n",
    "  - `accrf`    ‚Üí accuracy of Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c40179d4-d2c4-44be-b440-2a30c1cbc135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "SVR(kernel='linear')\n",
      "DecisionTreeRegressor(random_state=0)\n",
      "RandomForestRegressor(n_estimators=10, random_state=0)\n"
     ]
    }
   ],
   "source": [
    "rfelist=rfeFeature(indep_X,dep_Y,3)       \n",
    "\n",
    "acclin=[]\n",
    "accsvml=[]\n",
    "accsvmnl=[]\n",
    "accdes=[]\n",
    "accrf=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e804745-4cff-442a-9d0c-eebdbe8b68ea",
   "metadata": {},
   "source": [
    "### Model Training & Evaluation  \n",
    "Trained Linear, SVM, Decision Tree, and Random Forest models on RFE-selected features.  \n",
    "Collected R¬≤ scores for each model and summarized results in `result`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d97f890e-bfd4-4142-ac90-25870a84e593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mukil\\AppData\\Local\\Temp\\ipykernel_19048\\1005540822.py:8: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['Linear'][idex]=acclog[number]\n",
      "C:\\Users\\mukil\\AppData\\Local\\Temp\\ipykernel_19048\\1005540822.py:9: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['SVMl'][idex]=accsvml[number]\n",
      "C:\\Users\\mukil\\AppData\\Local\\Temp\\ipykernel_19048\\1005540822.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['Decision'][idex]=accdes[number]\n",
      "C:\\Users\\mukil\\AppData\\Local\\Temp\\ipykernel_19048\\1005540822.py:11: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['Random'][idex]=accrf[number]\n"
     ]
    }
   ],
   "source": [
    "for i in rfelist:   \n",
    "    X_train, X_test, y_train, y_test=split_scalar(i,dep_Y)  \n",
    "    r2_lin=Linear(X_train,y_train,X_test)\n",
    "    acclin.append(r2_lin)\n",
    "    \n",
    "    r2_sl=svm_linear(X_train,y_train,X_test)    \n",
    "    accsvml.append(r2_sl)\n",
    "    \n",
    "    r2_NL=svm_NL(X_train,y_train,X_test)\n",
    "    accsvmnl.append(r2_NL)\n",
    "    \n",
    "    r2_d=Decision(X_train,y_train,X_test)\n",
    "    accdes.append(r2_d)\n",
    "    \n",
    "    r2_r=random(X_train,y_train,X_test)\n",
    "    accrf.append(r2_r)\n",
    "    \n",
    "    \n",
    "result=rfe_regression(acclin,accsvml,accdes,accrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b82f18-56fb-4e81-af9e-7b41b007cb78",
   "metadata": {},
   "source": [
    "# Print the final comparison of model accuracies after RFE-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a451b3e7-7de4-4c5c-84e3-20ee69bf9b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear</th>\n",
       "      <td>0.441961</td>\n",
       "      <td>0.262153</td>\n",
       "      <td>0.441961</td>\n",
       "      <td>0.441816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.441961</td>\n",
       "      <td>0.262153</td>\n",
       "      <td>0.441961</td>\n",
       "      <td>0.441816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.664893</td>\n",
       "      <td>0.609652</td>\n",
       "      <td>0.965961</td>\n",
       "      <td>0.916304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.676174</td>\n",
       "      <td>0.670691</td>\n",
       "      <td>0.933504</td>\n",
       "      <td>0.887256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Linear      SVMl  Decision    Random\n",
       "Linear        0.441961  0.262153  0.441961  0.441816\n",
       "SVC           0.441961  0.262153  0.441961  0.441816\n",
       "Random        0.664893  0.609652  0.965961  0.916304\n",
       "DecisionTree  0.676174  0.670691  0.933504  0.887256"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca63ad4-244b-49c1-9bc6-08fa560b8825",
   "metadata": {},
   "source": [
    "## üîé Feature Selection & Model Performance\n",
    "\n",
    "### Feature Selection\n",
    "- We applied **Recursive Feature Elimination (RFE)** to select the **top 3 features**.\n",
    "- RFE works by:\n",
    "  1. Fitting a model,\n",
    "  2. Ranking features by importance,\n",
    "  3. Eliminating the least important features step by step,\n",
    "  4. Keeping only the best `n_features_to_select`.\n",
    "- This reduces noise and helps models focus on the most relevant predictors.\n",
    "\n",
    "---\n",
    "\n",
    "### Model Performance (R¬≤ Scores)\n",
    "\n",
    "| Model           | Avg R¬≤ Range |\n",
    "|-----------------|--------------|\n",
    "| Linear Regression | ~0.26 ‚Äì 0.44 |\n",
    "| SVM (linear)      | ~0.26 ‚Äì 0.44 |\n",
    "| Decision Tree     | ~0.67 ‚Äì 0.93 |\n",
    "| Random Forest     | **~0.66 ‚Äì 0.96** |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Observations\n",
    "- **Linear Regression / SVM** ‚Üí weak performance, not capturing complexity well.  \n",
    "- **Decision Tree** ‚Üí strong results, good at handling non-linear relationships.  \n",
    "- **Random Forest** ‚Üí üèÜ best performer overall, highest R¬≤, most reliable across runs.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Conclusion\n",
    "- **RFE** successfully reduced the dataset to the **3 most important features**.  \n",
    "- **Random Forest** performed the best, followed closely by **Decision Tree**.  \n",
    "- Simple models like **Linear Regression** and **SVM** were less effective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc4547e-0d45-4d25-8754-89ce790fc070",
   "metadata": {},
   "source": [
    "### RFE with Top 4 Features  \n",
    "Selects the 4 most important features using Recursive Feature Elimination (RFE).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81c6e1d2-2a88-4d99-81c6-b54157d05424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "SVR(kernel='linear')\n",
      "DecisionTreeRegressor(random_state=0)\n",
      "RandomForestRegressor(n_estimators=10, random_state=0)\n"
     ]
    }
   ],
   "source": [
    "# Run RFE for top 4 features\n",
    "rfelist_4 = rfeFeature(indep_X, dep_Y, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf1a90d-a43e-47e3-b30c-ef55e64c962a",
   "metadata": {},
   "source": [
    "### RFE with Top 5 Features  \n",
    "Selects the 5 most important features using Recursive Feature Elimination (RFE).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd10ca09-db01-4587-9f84-437c9f8ca1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "SVR(kernel='linear')\n",
      "DecisionTreeRegressor(random_state=0)\n",
      "RandomForestRegressor(n_estimators=10, random_state=0)\n",
      "LinearRegression()\n",
      "SVR(kernel='linear')\n",
      "DecisionTreeRegressor(random_state=0)\n",
      "RandomForestRegressor(n_estimators=10, random_state=0)\n"
     ]
    }
   ],
   "source": [
    "# Run RFE for top 5 features\n",
    "rfelist_5 = rfeFeature(indep_X, dep_Y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "012d1ef7-4132-496d-b324-16f3cca13684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mukil\\AppData\\Local\\Temp\\ipykernel_19048\\1005540822.py:8: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['Linear'][idex]=acclog[number]\n",
      "C:\\Users\\mukil\\AppData\\Local\\Temp\\ipykernel_19048\\1005540822.py:9: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['SVMl'][idex]=accsvml[number]\n",
      "C:\\Users\\mukil\\AppData\\Local\\Temp\\ipykernel_19048\\1005540822.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['Decision'][idex]=accdes[number]\n",
      "C:\\Users\\mukil\\AppData\\Local\\Temp\\ipykernel_19048\\1005540822.py:11: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['Random'][idex]=accrf[number]\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists for 4 features\n",
    "acclin_4, accsvml_4, accsvmnl_4, accdes_4, accrf_4 = [], [], [], [], []\n",
    "\n",
    "for i in rfelist_4:\n",
    "    X_train, X_test, y_train, y_test = split_scalar(i, dep_Y)\n",
    "\n",
    "    acclin_4.append(Linear(X_train, y_train, X_test))\n",
    "    accsvml_4.append(svm_linear(X_train, y_train, X_test))\n",
    "    accsvmnl_4.append(svm_NL(X_train, y_train, X_test))\n",
    "    accdes_4.append(Decision(X_train, y_train, X_test))\n",
    "    accrf_4.append(random(X_train, y_train, X_test))\n",
    "\n",
    "result_4 = rfe_regression(acclin_4, accsvml_4, accdes_4, accrf_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b8ce24d-e59e-4c44-90f0-12f46398a329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists for 5 features\n",
    "acclin_5, accsvml_5, accsvmnl_5, accdes_5, accrf_5 = [], [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b66d093-05c7-44a9-bc09-412c130a642f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mukil\\AppData\\Local\\Temp\\ipykernel_19048\\1005540822.py:8: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['Linear'][idex]=acclog[number]\n",
      "C:\\Users\\mukil\\AppData\\Local\\Temp\\ipykernel_19048\\1005540822.py:9: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['SVMl'][idex]=accsvml[number]\n",
      "C:\\Users\\mukil\\AppData\\Local\\Temp\\ipykernel_19048\\1005540822.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['Decision'][idex]=accdes[number]\n",
      "C:\\Users\\mukil\\AppData\\Local\\Temp\\ipykernel_19048\\1005540822.py:11: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['Random'][idex]=accrf[number]\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists for 5 features\n",
    "acclin_5, accsvml_5, accsvmnl_5, accdes_5, accrf_5 = [], [], [], [], []\n",
    "\n",
    "for i in rfelist_5:\n",
    "    X_train, X_test, y_train, y_test = split_scalar(i, dep_Y)\n",
    "\n",
    "    acclin_5.append(Linear(X_train, y_train, X_test))\n",
    "    accsvml_5.append(svm_linear(X_train, y_train, X_test))\n",
    "    accsvmnl_5.append(svm_NL(X_train, y_train, X_test))\n",
    "    accdes_5.append(Decision(X_train, y_train, X_test))\n",
    "    accrf_5.append(random(X_train, y_train, X_test))\n",
    "\n",
    "result_5 = rfe_regression(acclin_5, accsvml_5, accdes_5, accrf_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab4e4b7-ee09-4193-9ffe-0d49d12972e8",
   "metadata": {},
   "source": [
    "### Print RFE Results  \n",
    "Displays the model performance results separately for top 4 features and top 5 features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ceca199e-92d9-43d2-8d5e-daf0f57f3f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with 4 features:\n",
      "                Linear      SVMl  Decision    Random\n",
      "Linear         0.60401  0.457046  0.776711  0.776492\n",
      "SVC            0.60401  0.457046  0.776711  0.776492\n",
      "Random        0.671727  0.628963  0.835247    0.8403\n",
      "DecisionTree  0.681563  0.614992   0.96711  0.923559\n"
     ]
    }
   ],
   "source": [
    "print(\"Results with 4 features:\")\n",
    "print(result_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3396704a-e946-4915-98f1-662ae4ce0efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results with 5 features:\n",
      "                Linear      SVMl  Decision    Random\n",
      "Linear        0.620124  0.457136   0.77924  0.780135\n",
      "SVC           0.604508  0.456871  0.776474  0.776745\n",
      "Random        0.674403  0.628206  0.696181  0.815538\n",
      "DecisionTree  0.686361  0.643365  0.836806  0.845303\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResults with 5 features:\")\n",
    "print(result_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda5b6fb-9ee2-43cd-a619-8dec51ab9bef",
   "metadata": {},
   "source": [
    "### Comparison of RFE Results  \n",
    "Combines model performance results for top 4 and 5 features into a single side-by-side table.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43214dc7-97ec-4cc5-a95f-daaa0cabdab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Top 3 Features</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Top 4 Features</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Top 5 Features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Linear</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "      <th>Linear</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "      <th>Linear</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear</th>\n",
       "      <td>0.441961</td>\n",
       "      <td>0.262153</td>\n",
       "      <td>0.441961</td>\n",
       "      <td>0.441816</td>\n",
       "      <td>0.60401</td>\n",
       "      <td>0.457046</td>\n",
       "      <td>0.776711</td>\n",
       "      <td>0.776492</td>\n",
       "      <td>0.620124</td>\n",
       "      <td>0.457136</td>\n",
       "      <td>0.77924</td>\n",
       "      <td>0.780135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.441961</td>\n",
       "      <td>0.262153</td>\n",
       "      <td>0.441961</td>\n",
       "      <td>0.441816</td>\n",
       "      <td>0.60401</td>\n",
       "      <td>0.457046</td>\n",
       "      <td>0.776711</td>\n",
       "      <td>0.776492</td>\n",
       "      <td>0.604508</td>\n",
       "      <td>0.456871</td>\n",
       "      <td>0.776474</td>\n",
       "      <td>0.776745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.664893</td>\n",
       "      <td>0.609652</td>\n",
       "      <td>0.965961</td>\n",
       "      <td>0.916304</td>\n",
       "      <td>0.671727</td>\n",
       "      <td>0.628963</td>\n",
       "      <td>0.835247</td>\n",
       "      <td>0.8403</td>\n",
       "      <td>0.674403</td>\n",
       "      <td>0.628206</td>\n",
       "      <td>0.696181</td>\n",
       "      <td>0.815538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.676174</td>\n",
       "      <td>0.670691</td>\n",
       "      <td>0.933504</td>\n",
       "      <td>0.887256</td>\n",
       "      <td>0.681563</td>\n",
       "      <td>0.614992</td>\n",
       "      <td>0.96711</td>\n",
       "      <td>0.923559</td>\n",
       "      <td>0.686361</td>\n",
       "      <td>0.643365</td>\n",
       "      <td>0.836806</td>\n",
       "      <td>0.845303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Top 3 Features                               Top 4 Features  \\\n",
       "                     Linear      SVMl  Decision    Random         Linear   \n",
       "Linear             0.441961  0.262153  0.441961  0.441816        0.60401   \n",
       "SVC                0.441961  0.262153  0.441961  0.441816        0.60401   \n",
       "Random             0.664893  0.609652  0.965961  0.916304       0.671727   \n",
       "DecisionTree       0.676174  0.670691  0.933504  0.887256       0.681563   \n",
       "\n",
       "                                           Top 5 Features                      \\\n",
       "                  SVMl  Decision    Random         Linear      SVMl  Decision   \n",
       "Linear        0.457046  0.776711  0.776492       0.620124  0.457136   0.77924   \n",
       "SVC           0.457046  0.776711  0.776492       0.604508  0.456871  0.776474   \n",
       "Random        0.628963  0.835247    0.8403       0.674403  0.628206  0.696181   \n",
       "DecisionTree  0.614992   0.96711  0.923559       0.686361  0.643365  0.836806   \n",
       "\n",
       "                        \n",
       "                Random  \n",
       "Linear        0.780135  \n",
       "SVC           0.776745  \n",
       "Random        0.815538  \n",
       "DecisionTree  0.845303  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine results for top 3, 4, and 5 features\n",
    "comparison = pd.concat(\n",
    "    {\"Top 3 Features\": result, \"Top 4 Features\": result_4, \"Top 5 Features\": result_5},\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3428b1-8016-4707-a12d-f4cd37f41037",
   "metadata": {},
   "source": [
    "### üìä RFE Feature Comparison (Top 3 vs Top 4 vs Top 5 Features)\n",
    "\n",
    "- **Top 3 Features**  \n",
    "  - Linear & SVM models performed weakly (R¬≤ ~0.26‚Äì0.44).  \n",
    "  - Decision Tree and Random Forest gave strong results (R¬≤ ~0.87‚Äì0.96).  \n",
    "\n",
    "- **Top 4 Features**  \n",
    "  - Noticeable improvement in Linear and SVM models (R¬≤ up to ~0.60).  \n",
    "  - Decision Tree achieved its best score (~0.97).  \n",
    "  - Random Forest remained consistently strong (~0.84‚Äì0.92).  \n",
    "\n",
    "- **Top 5 Features**  \n",
    "  - Linear and SVM stayed around similar levels (~0.60).  \n",
    "  - Decision Tree dropped slightly compared to 4 features (~0.83‚Äì0.84).  \n",
    "  - Random Forest also decreased a bit (~0.81).  \n",
    "\n",
    "### ‚úÖ Conclusion\n",
    "- **Best Performance** ‚Üí **Decision Tree with Top 4 Features** (R¬≤ ‚âà 0.97).  \n",
    "- **Most Consistent** ‚Üí **Random Forest**, which gave solid performance across all feature sets.  \n",
    "- **Linear & SVM** ‚Üí Improved when moving from 3 ‚Üí 4 features, but overall still weaker compared to tree-based models.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
