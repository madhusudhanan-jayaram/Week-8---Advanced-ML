{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "23d05e6e-bfd6-49a4-9364-b2eef6a57a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a98cac29-39ea-4379-8cce-68c84abb86a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path=\"Social_Network_Ads.csv\"):\n",
    "    dataset = pd.read_csv(path)\n",
    "    X = dataset.iloc[:, [2, 3]].values   \n",
    "    y = dataset.iloc[:, 4].values     \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=0, stratify=y\n",
    "    )\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ba8feee9-bd5d-4308-bfe3-ab3ec27e4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kpca(X_train, X_test, n_components=2, kernel=\"rbf\"):\n",
    "    kpca = KernelPCA(n_components=n_components, kernel=kernel)\n",
    "    X_train_kpca = kpca.fit_transform(X_train)\n",
    "    X_test_kpca = kpca.transform(X_test)\n",
    "    return X_train_kpca, X_test_kpca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f39f7a3f-a48e-4c6c-909b-ba21f6002f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(name, model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n{name} | Accuracy: {round(acc, 4)}\")\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    # return BOTH the trained model and accuracy\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "15f6a0c2-9fcf-4310-8e3a-7e2b8653ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(X, y, classifier, title):\n",
    "    X1, X2 = np.meshgrid(\n",
    "        np.arange(start=X[:, 0].min() - 1, stop=X[:, 0].max() + 1, step=0.01),\n",
    "        np.arange(start=X[:, 1].min() - 1, stop=X[:, 1].max() + 1, step=0.01)\n",
    "    )\n",
    "\n",
    "    plt.contourf(\n",
    "        X1, X2,\n",
    "        classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "        alpha=0.75, cmap=ListedColormap(('red', 'green', 'blue'))\n",
    "    )\n",
    "    plt.xlim(X1.min(), X1.max())\n",
    "    plt.ylim(X2.min(), X2.max())\n",
    "\n",
    "    for i, j in enumerate(np.unique(y)):\n",
    "        plt.scatter(\n",
    "            X[y == j, 0], X[y == j, 1],\n",
    "            c=ListedColormap(('red', 'green', 'blue'))(i), label=j\n",
    "        )\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"LD1\")\n",
    "    plt.ylabel(\"LD2\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "68244148-257d-44c6-aab9-bc07157c8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(kda_list=[1]):\n",
    "    # 1. Load dataset\n",
    "    X_train, X_test, y_train, y_test = load_data()\n",
    "\n",
    "    # 2. Define models\n",
    "    models = [\n",
    "        (\"Logistic Regression\", LogisticRegression(max_iter=1000, random_state=0)),\n",
    "        (\"SVM (Linear)\", SVC(kernel=\"linear\", random_state=0)),\n",
    "        (\"KNN\", KNeighborsClassifier(n_neighbors=5)),\n",
    "        (\"Decision Tree\", DecisionTreeClassifier(random_state=0)),\n",
    "        (\"Random Forest\", RandomForestClassifier(n_estimators=200, random_state=0)),\n",
    "        (\"Gaussian NB\", GaussianNB()),\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # 3. Loop over KDA components\n",
    "    for n in kda_list:\n",
    "        print(f\"\\n==== KDA Components = {n} ====\")\n",
    "\n",
    "        # Apply KDA (KernelPCA -> LDA)\n",
    "        X_train_kpca, X_test_kpca = apply_kpca(X_train, X_test, n_components=n)\n",
    "\n",
    "        # Train and evaluate each model\n",
    "        for name, clf in models:\n",
    "            acc = train_and_eval(name, clf, X_train_kpca, y_train, X_test_kpca, y_test)\n",
    "            results.append([n, name, acc])\n",
    "\n",
    "    # 4. Build results DataFrame\n",
    "    df = pd.DataFrame(results, columns=[\"KDA\", \"Model\", \"Accuracy\"])\n",
    "    print(\"\\n===== FINAL RESULTS TABLE =====\")\n",
    "    print(df.pivot(index=\"Model\", columns=\"KDA\", values=\"Accuracy\"))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4c82311c-695e-4bfd-af7d-1792e0abb1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== KDA Components = 1 ====\n",
      "\n",
      "Logistic Regression | Accuracy: 0.85\n",
      "Confusion Matrix:\n",
      " [[47  4]\n",
      " [ 8 21]]\n",
      "\n",
      "SVM (Linear) | Accuracy: 0.875\n",
      "Confusion Matrix:\n",
      " [[47  4]\n",
      " [ 6 23]]\n",
      "\n",
      "KNN | Accuracy: 0.8\n",
      "Confusion Matrix:\n",
      " [[44  7]\n",
      " [ 9 20]]\n",
      "\n",
      "Decision Tree | Accuracy: 0.7375\n",
      "Confusion Matrix:\n",
      " [[45  6]\n",
      " [15 14]]\n",
      "\n",
      "Random Forest | Accuracy: 0.7375\n",
      "Confusion Matrix:\n",
      " [[45  6]\n",
      " [15 14]]\n",
      "\n",
      "Gaussian NB | Accuracy: 0.8875\n",
      "Confusion Matrix:\n",
      " [[46  5]\n",
      " [ 4 25]]\n",
      "\n",
      "==== KDA Components = 2 ====\n",
      "\n",
      "Logistic Regression | Accuracy: 0.8625\n",
      "Confusion Matrix:\n",
      " [[47  4]\n",
      " [ 7 22]]\n",
      "\n",
      "SVM (Linear) | Accuracy: 0.8875\n",
      "Confusion Matrix:\n",
      " [[47  4]\n",
      " [ 5 24]]\n",
      "\n",
      "KNN | Accuracy: 0.875\n",
      "Confusion Matrix:\n",
      " [[46  5]\n",
      " [ 5 24]]\n",
      "\n",
      "Decision Tree | Accuracy: 0.775\n",
      "Confusion Matrix:\n",
      " [[45  6]\n",
      " [12 17]]\n",
      "\n",
      "Random Forest | Accuracy: 0.875\n",
      "Confusion Matrix:\n",
      " [[46  5]\n",
      " [ 5 24]]\n",
      "\n",
      "Gaussian NB | Accuracy: 0.9\n",
      "Confusion Matrix:\n",
      " [[47  4]\n",
      " [ 4 25]]\n",
      "\n",
      "===== FINAL RESULTS TABLE =====\n",
      "KDA                       1       2\n",
      "Model                              \n",
      "Decision Tree        0.7375  0.7750\n",
      "Gaussian NB          0.8875  0.9000\n",
      "KNN                  0.8000  0.8750\n",
      "Logistic Regression  0.8500  0.8625\n",
      "Random Forest        0.7375  0.8750\n",
      "SVM (Linear)         0.8750  0.8875\n"
     ]
    }
   ],
   "source": [
    "df_results = run_pipeline(kda_list=[1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c5ca2e-0571-4136-afca-4226ffa19c38",
   "metadata": {},
   "source": [
    "### ðŸ”Ž Observations\n",
    "- With **1 component**:  \n",
    "  - Best: **Gaussian NB (88.8%)**, **SVM (87.5%)**.  \n",
    "  - Logistic Regression was strong at 85%.  \n",
    "  - Decision Tree and Random Forest weakest (~73.8%).  \n",
    "\n",
    "- With **2 components**:  \n",
    "  - Accuracy improved for almost all models.  \n",
    "  - **Gaussian NB (90%)**, **SVM (88.8%)**, **Random Forest (87.5%)**, and **KNN (87.5%)** performed the best.  \n",
    "  - Logistic Regression improved slightly (86.3%).  \n",
    "  - Decision Tree remained the lowest at ~77.5%.  \n",
    "\n",
    "### âœ… Conclusion\n",
    "Using **2 KDA components** is better:  \n",
    "- **Gaussian NB and SVM** are consistently strong.  \n",
    "- **Random Forest and KNN** gained the most with 2 components.  \n",
    "- **Decision Tree** stayed weakest overall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
